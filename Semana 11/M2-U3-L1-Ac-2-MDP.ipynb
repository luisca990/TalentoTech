{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEjf6MPgd7/sSHVa7DT4vi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Js991K0oaRQi","executionInfo":{"status":"ok","timestamp":1724520506650,"user_tz":300,"elapsed":650,"user":{"displayName":"Luis Carlos Romero Cardenas","userId":"11570786301754282199"}},"outputId":"a7179665-c7e6-4ae5-c24b-ca3b928f0982"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[7 2]\n"," [0 1]\n"," [5 8]]\n","Estado actual: C\n","Acción: Arriba\n","Nuevo estado: A\n","Recompensa: 5\n"]}],"source":["import numpy as np\n","\n","estados=['A','B','C']\n","acciones=['Arriba','Abajo']\n","recompensas=np.random.randint(0,10,size=(len(estados),len(acciones)))\n","print(recompensas)\n","\n","\n","def transicion_aleatoria():\n","  return np.random.choice(estados)\n","\n","estado_actual=np.random.choice(estados)\n","accion=np.random.choice(acciones)\n","nuevo_estado=transicion_aleatoria()\n","recompensa=recompensas[estados.index(estado_actual),acciones.index(accion)]\n","\n","print(f\"Estado actual: {estado_actual}\")\n","print(f\"Acción: {accion}\")\n","print(f\"Nuevo estado: {nuevo_estado}\")\n","print(f\"Recompensa: {recompensa}\")"]},{"cell_type":"markdown","source":["# Conceptos de MDP"],"metadata":{"id":"955OpxBSbyJ2"}},{"cell_type":"code","source":["mdp={\n","  'estados':['A','B','C'],\n","  'acciones':['Arriba','Abajo'],\n","  'transiciones':{'A':{'Arriba':{'A':0.3, 'B':0.6, 'C':0.1}, 'Abajo':{'A':0.1, 'B':0.2, 'C':0.7}},\n","                 'B':{'Arriba':{'A':0.8, 'B':0.1, 'C':0.1}, 'Abajo':{'A':0.2, 'B':0.3, 'C':0.5}},\n","                 'C':{'Arriba':{'A':0.5, 'B':0.3, 'C':0.2}, 'Abajo':{'A':0.1, 'B':0.8, 'C':0.1}}}, # Add example transitions\n","  'recompensas':{'A':{'Arriba':{'A':1, 'B':2, 'C':3}, 'Abajo':{'A':4, 'B':5, 'C':6}},\n","                 'B':{'Arriba':{'A':7, 'B':8, 'C':9}, 'Abajo':{'A':0, 'B':1, 'C':2}},\n","                 'C':{'Arriba':{'A':3, 'B':4, 'C':5}, 'Abajo':{'A':6, 'B':7, 'C':8}}}  # Add example rewards\n","}\n","def calcular_valor_estado(mdp,gamma=0.9, tetha=0.01):\n","  valores={estado:0 for estado in mdp['estados']}\n","  while True:\n","    delta=0\n","    for estado in mdp['estados']:\n","      valor_previo=valores[estado]\n","      valores[estado]=sum(mdp['transiciones'][estado][accion][nuevo_estado]*(mdp['recompensas'][estado][accion][nuevo_estado]+gamma*valores[nuevo_estado]) for accion in mdp['acciones'] for nuevo_estado in mdp['estados'])\n","      delta=max(delta,abs(valor_previo-valores[estado]))\n","    if delta<tetha:\n","      break\n","  return valores\n","\n","valores_estados=calcular_valor_estado(mdp)\n","print(valores_estados)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFdjUfs2bd1N","executionInfo":{"status":"ok","timestamp":1724521230102,"user_tz":300,"elapsed":308,"user":{"displayName":"Luis Carlos Romero Cardenas","userId":"11570786301754282199"}},"outputId":"847a0bb8-3096-4a1c-a4b7-e114dfab4acd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'A': inf, 'B': inf, 'C': inf}\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","mdp={\n","  'estados':['A','B','C'],\n","  'acciones':['Arriba','Abajo'],\n","  'transiciones':{'A':{'Arriba':{'A':0.3, 'B':0.6, 'C':0.1}, 'Abajo':{'A':0.1, 'B':0.2, 'C':0.7}},\n","                 'B':{'Arriba':{'A':0.8, 'B':0.1, 'C':0.1}, 'Abajo':{'A':0.2, 'B':0.3, 'C':0.5}},\n","                 'C':{'Arriba':{'A':0.5, 'B':0.3, 'C':0.2}, 'Abajo':{'A':0.1, 'B':0.8, 'C':0.1}}}, # Add example transitions\n","  'recompensas':{'A':{'Arriba':{'A':1, 'B':2, 'C':3}, 'Abajo':{'A':4, 'B':5, 'C':6}},\n","                 'B':{'Arriba':{'A':7, 'B':8, 'C':9}, 'Abajo':{'A':0, 'B':1, 'C':2}},\n","                 'C':{'Arriba':{'A':3, 'B':4, 'C':5}, 'Abajo':{'A':6, 'B':7, 'C':8}}}  # Add example rewards\n","}\n","\n","def calcular_valor_estado(mdp,gamma=0.9, tetha=0.01):\n","  valores={estado:0 for estado in mdp['estados']}\n","  while True:\n","    delta=0\n","    for estado in mdp['estados']:\n","      valor_previo=valores[estado]\n","      valores[estado]=sum(mdp['transiciones'][estado][accion][nuevo_estado]*(mdp['recompensas'][estado][accion][nuevo_estado]+gamma*valores[nuevo_estado]) for accion in mdp['acciones'] for nuevo_estado in mdp['estados'])\n","      delta=max(delta,abs(valor_previo-valores[estado]))\n","    if delta<tetha:\n","      break\n","  return valores\n","\n","valores_estados=calcular_valor_estado(mdp)\n","print(valores_estados)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Z0xTqxueQ7A","executionInfo":{"status":"ok","timestamp":1724521192343,"user_tz":300,"elapsed":301,"user":{"displayName":"Luis Carlos Romero Cardenas","userId":"11570786301754282199"}},"outputId":"68ac7093-0a78-4d1e-a017-538681be97f9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{'A': inf, 'B': inf, 'C': inf}\n"]}]},{"cell_type":"markdown","source":["# Propiedades de Markov"],"metadata":{"id":"GlbdGKi8dyhG"}},{"cell_type":"code","source":["def verificar_propiedad_markov(mdp):\n","  for estado in mdp['estados']:\n","    for accion in mdp['acciones']:\n","      suma_probabilidades=sum(mdp['transiciones'][estado][accion].values())\n","      if not np.isclose(suma_probabilidades,1):\n","        return False\n","  return True\n","\n","print(\"Cumple con la propiedad de Markov\")\n","verificar_propiedad_markov(mdp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkCrbyP8c8OE","executionInfo":{"status":"ok","timestamp":1724521304185,"user_tz":300,"elapsed":310,"user":{"displayName":"Luis Carlos Romero Cardenas","userId":"11570786301754282199"}},"outputId":"60be2962-a659-409d-8dc6-427103b56ca5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cumple con la propiedad de Markov\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Propiedad de Recompensa"],"metadata":{"id":"tU3ZGYaeevvT"}},{"cell_type":"code","source":["def calcular_recompensa_promedio(mdp):\n","  recompensa_total=0\n","  total_acciones=0\n","  for estado in mdp['estados']:\n","    for accion in mdp['acciones']:\n","      for nuevo_estado in mdp['estados']:\n","        recompensa_total+=mdp['recompensas'][estado][accion][nuevo_estado]\n","        total_acciones+=1\n","  return recompensa_total/total_acciones\n","\n","print(\"Recompensa promedio:\",calcular_recompensa_promedio(mdp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKKIuCLMes4B","executionInfo":{"status":"ok","timestamp":1724521466485,"user_tz":300,"elapsed":301,"user":{"displayName":"Luis Carlos Romero Cardenas","userId":"11570786301754282199"}},"outputId":"0cc5d3a8-f8db-4415-e629-414b3621ec36"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Recompensa promedio: 4.5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8703_sfSfUeT"},"execution_count":null,"outputs":[]}]}